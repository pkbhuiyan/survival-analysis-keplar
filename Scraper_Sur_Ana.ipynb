{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_1967 = \"http://www.pro-football-reference.com/years/1967/draft.htm\"\n",
    "# html = urlopen(url_1967)\n",
    "# soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_headers = [th.getText() for th in \n",
    "#                   soup.findAll('tr', limit=2)[1].findAll('th')]\n",
    "# column_headers.extend([\"Player_NFL_Link\", \"Player_NCAA_Link\"])\n",
    "# column_headers=[x for x in column_headers if x]\n",
    "# table_rows = soup.select(\"#drafts tr\")[1:]\n",
    "def extract_player_data(table_rows):\n",
    "    player_data = []\n",
    "    \n",
    "    for row in table_rows:  # for each row do the following\n",
    "\n",
    "        player_list = [td.get_text()[:-4] if td.get_text().endswith(\" HOF\") \n",
    "                       else td.get_text() for td in row.find_all([\"td\",\"th\"])]\n",
    "        if not player_list:\n",
    "            continue\n",
    "        \n",
    "        links_dict = {(link.get_text()[:-4]   # exclude the last 4 characters\n",
    "                       if link.get_text().endswith(\" HOF\")  # if they are \" HOF\"\n",
    "                       # else get all text, set thet as the dictionary key \n",
    "                       # and set the url as the value\n",
    "                       else link.get_text()) : link[\"href\"] \n",
    "                       for link in row.find_all(\"a\", href=True)}\n",
    "        \n",
    "        player_list.append(links_dict.get(player_list[3], \" \"))\n",
    "        \n",
    "        player_list.append(links_dict.get(\"College Stats\", \" \"))\n",
    "        \n",
    "        player_data.append(player_list)\n",
    "        \n",
    "    return player_data\n",
    "# extract the data we want\n",
    "# data = extract_player_data(table_rows)\n",
    "# and then store it in a DataFrame\n",
    "# df = pd.DataFrame(data, columns=column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draft_dfs_list = []\n",
    "\n",
    "# a list to store any errors that may come up while scraping\n",
    "errors_list = []\n",
    "# The url template that we pass in the draft year inro\n",
    "url_template = \"http://www.pro-football-reference.com/years/{year}/draft.htm\"\n",
    "\n",
    "# for each year \n",
    "for year in range(1997, 2018): \n",
    "    \n",
    "    # Use try/except block to catch and inspect any urls that cause an error\n",
    "    try:\n",
    "        # get the draft url\n",
    "        url = url_template.format(year=year)\n",
    "\n",
    "        # get the html\n",
    "        html = urlopen(url)\n",
    "\n",
    "        # create the BeautifulSoup object\n",
    "        soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "        # get the column headers\n",
    "        column_headers = [th.getText() for th in \n",
    "                          soup.findAll('tr', limit=2)[1].findAll('th')]\n",
    "        column_headers.extend([\"Player_NFL_Link\", \"Player_NCAA_Link\"])\n",
    "\n",
    "        # select the data from the table using the '#drafts tr' CSS selector\n",
    "        table_rows = soup.select(\"#drafts tr\")[2:] \n",
    "\n",
    "        # extract the player data from the table rows\n",
    "        player_data = extract_player_data(table_rows)\n",
    "\n",
    "        # create the dataframe for the current years draft\n",
    "        year_df = pd.DataFrame(player_data, columns=column_headers)\n",
    "\n",
    "        # if it is a draft from before 1994 then add a Tkl column at the \n",
    "        # 24th position\n",
    "        if year < 1994:\n",
    "            year_df.insert(24, \"Tkl\", \"\")\n",
    "\n",
    "        # add the year of the draft to the dataframe\n",
    "        year_df.insert(0, \"Draft_Yr\", year)\n",
    "\n",
    "        # append the current dataframe to the list of dataframes\n",
    "        draft_dfs_list.append(year_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Store the url and the error it causes in a list\n",
    "        error =[url, e] \n",
    "        # then append it to the list of errors\n",
    "        errors_list.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all drafts in one DataFrame\n",
    "draft_df = pd.concat(draft_dfs_list, ignore_index=True)\n",
    "draft_df.drop(draft_df[draft_df.To == 'To'].index, inplace=True)\n",
    "player_ids = draft_df.Player_NFL_Link.str.extract(\"/.*/.*/(.*)\\.\",expand=False)\n",
    "draft_df[\"Player_Id\"] = player_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[]\n",
    "k=[]\n",
    "t=draft_df.To.tolist()\n",
    "d=draft_df.Draft_Yr.tolist()\n",
    "for i in range(0,len(t)):\n",
    "    \n",
    "    if t[i] == '':\n",
    "        f.append(0)\n",
    "        k.append(0)\n",
    "    else:\n",
    "        s=int(t[i])-d[i]\n",
    "        f.append(s+1)\n",
    "        k.append(1)\n",
    "draft_df['duration'] = f\n",
    "draft_df['retired'] = k\n",
    "draft_df.drop(['Player_NFL_Link','Player_NCAA_Link',''], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_df.to_csv('main-big-1997-2017-s.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
